{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Read-data\" data-toc-modified-id=\"Read-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Read data</a></span></li><li><span><a href=\"#Select-columns-and-drop-nans\" data-toc-modified-id=\"Select-columns-and-drop-nans-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Select columns and drop nans</a></span></li><li><span><a href=\"#Encoding\" data-toc-modified-id=\"Encoding-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Encoding</a></span></li><li><span><a href=\"#Assembler\" data-toc-modified-id=\"Assembler-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Assembler</a></span></li><li><span><a href=\"#Create-pipeline\" data-toc-modified-id=\"Create-pipeline-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Create pipeline</a></span></li><li><span><a href=\"#Model-evaluation\" data-toc-modified-id=\"Model-evaluation-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Model evaluation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:25.344240Z",
     "start_time": "2019-09-18T23:17:22.074183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('numpy', '1.17.1'), ('pandas', '0.25.1'), ('pyspark', '2.4.4')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf # @udf(\"integer\") def myfunc(x,y): return x - y\n",
    "from pyspark.sql import functions as F # stddev format_number date_format, dayofyear, when\n",
    "from pyspark.sql.types import StructField, StringType, IntegerType, StructType\n",
    "\n",
    "print([(x.__name__,x.__version__) for x in [np, pd, pyspark]])\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.appName('titanic').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "sc.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler, VectorIndexer,\n",
    "                               OneHotEncoder, StringIndexer)\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:25.473048Z",
     "start_time": "2019-09-18T23:17:25.345957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\r\n",
      "1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 ../data/titanic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:29.319776Z",
     "start_time": "2019-09-18T23:17:25.475073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('../data/titanic.csv',header=True,inferSchema=True)\n",
    "print(df.count())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:29.355747Z",
     "start_time": "2019-09-18T23:17:29.321409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:29.406192Z",
     "start_time": "2019-09-18T23:17:29.363735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select columns and drop nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:29.481429Z",
     "start_time": "2019-09-18T23:17:29.412579Z"
    }
   },
   "outputs": [],
   "source": [
    "my_cols = [ 'Survived', 'Pclass', 'Sex', 'Age',\n",
    "           'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "df = df.select(my_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:29.514299Z",
     "start_time": "2019-09-18T23:17:29.484926Z"
    }
   },
   "outputs": [],
   "source": [
    "my_final_data = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:29.710051Z",
     "start_time": "2019-09-18T23:17:29.516873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+----+-----+-----+----+--------+\n",
      "|Survived|Pclass| Sex| Age|SibSp|Parch|Fare|Embarked|\n",
      "+--------+------+----+----+-----+-----+----+--------+\n",
      "|       0|     3|male|22.0|    1|    0|7.25|       S|\n",
      "+--------+------+----+----+-----+-----+----+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:29.827517Z",
     "start_time": "2019-09-18T23:17:29.711712Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler, VectorIndexer,\n",
    "                               OneHotEncoder, StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:29.857408Z",
     "start_time": "2019-09-18T23:17:29.829263Z"
    }
   },
   "outputs": [],
   "source": [
    "gender_indexer = StringIndexer(inputCol='Sex', outputCol='Sex_index')\n",
    "\n",
    "gender_encoder = OneHotEncoder(inputCol='Sex_index', outputCol='Sex_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:29.873816Z",
     "start_time": "2019-09-18T23:17:29.859146Z"
    }
   },
   "outputs": [],
   "source": [
    "embark_indexer = StringIndexer(inputCol='Embarked', outputCol='Embarked_index')\n",
    "\n",
    "embark_encoder = OneHotEncoder(inputCol='Embarked_index', outputCol='Embarked_vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:45.771836Z",
     "start_time": "2019-09-18T23:17:45.761360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_final_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:54.002135Z",
     "start_time": "2019-09-18T23:17:53.993198Z"
    }
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Pclass','Sex_vec','Embarked_vec',\n",
    "                                      'Age','SibSp','Parch','Fare'],\n",
    "                           outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:54.630634Z",
     "start_time": "2019-09-18T23:17:54.625757Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:55.241748Z",
     "start_time": "2019-09-18T23:17:55.230069Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features',labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:55.747714Z",
     "start_time": "2019-09-18T23:17:55.744225Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[gender_indexer, embark_indexer,\n",
    "                           gender_encoder, embark_encoder,\n",
    "                           assembler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:56.371882Z",
     "start_time": "2019-09-18T23:17:56.329167Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = my_final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:17:59.372339Z",
     "start_time": "2019-09-18T23:17:56.873502Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:21:12.718024Z",
     "start_time": "2019-09-18T23:21:12.280246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+------+--------+---------+--------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|  Fare|Embarked|Sex_index|Embarked_index|      Sex_vec| Embarked_vec|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+------+----+-----+-----+------+--------+---------+--------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|     1|female| 2.0|    1|    2|151.55|       S|      1.0|           0.0|    (1,[],[])|(2,[0],[1.0])|[1.0,0.0,1.0,0.0,...|[-4.0693712215344...|[0.01680103157033...|       1.0|\n",
      "|       0|     1|  male|19.0|    1|    0|  53.1|       S|      0.0|           0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,1.0,0.0,...|[-0.4982229035736...|[0.37795838384935...|       1.0|\n",
      "+--------+------+------+----+-----+-----+------+--------+---------+--------------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = lr_model.transform(test)\n",
    "results.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:19:24.267699Z",
     "start_time": "2019-09-18T23:19:24.262324Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:19:54.438247Z",
     "start_time": "2019-09-18T23:19:54.423111Z"
    }
   },
   "outputs": [],
   "source": [
    "bc_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                       labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:22:06.964278Z",
     "start_time": "2019-09-18T23:22:06.708820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Survived|prediction|\n",
      "+--------+----------+\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select('Survived','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T23:22:28.879328Z",
     "start_time": "2019-09-18T23:22:28.563444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7454212454212453"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = bc_eval.evaluate(results)\n",
    "auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spk)",
   "language": "python",
   "name": "spk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
